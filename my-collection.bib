@inproceedings{Roden2020,
address = {Tampa, FL, USA},
author = {Roden, William and Layman, Lucas},
booktitle = {Proceedings of the 2020 ACM Southeast Conference (ACMSE 2020)},
doi = {10.1145/3374135.3385301},
file = {:C$\backslash$:/Users/laymanl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Roden, Layman - 2020 - Cry Wolf Toward an Experimentation Platform and Dataset for Human Factors in Cyber Security Analysis(2).pdf:pdf},
pages = {264--267},
publisher = {ACM},
title = {{Cry Wolf : Toward an Experimentation Platform and Dataset for Human Factors in Cyber Security Analysis}},
url = {https://arxiv.org/abs/2002.10530},
year = {2020}
}
@misc{Roden2019a,
author = {Roden, William and Layman, Lucas},
booktitle = {GitHub},
title = {{The Cry Wolf IDS Simulator - An environment for conducting controlled experiments of cyber security analysis tasks}},
url = {https://uncw-hfcs.github.io/ids-simulator/},
urldate = {2020-09-16},
year = {2019}
}

@inproceedings{Layman2020,
abstract = {Factors driving success and failure in CS1 are the subject of much study but less so for CS2. This paper investigates the transition from CS1 to CS2 in search of leading indicators of success in CS2. Both CS1 and CS2 at the University of North Carolina Wilmington (UNCW) are taught in Python with annual enrollments of 300 and 150 respectively. In this paper, we report on the following research questions: (1) Are CS1 grades indicators of CS2 grades? (2) Does a quantitative relationship exist between CS2 course grade and a modified version of the SCS1 concept inventory? (3) What are the most challenging aspects of CS2, and how well does CS1 prepare students for CS2 from the student's perspective? We provide a quantitative analysis of 2300 CS1 and CS2 course grades from 2013â€“2019. In Spring 2019, we administered a modified version of the SCS1 concept inventory to 44 students in the first week of CS2. Further, 69 students completed an exit questionnaire at the conclusion of CS2 to gain qualitative student feedback on their challenges in CS2 and on how well CS1 prepared them for CS2. We find that 56{\%} of students' grades were lower in CS2 than CS1, 18{\%} improved their grades, and 26{\%} earned the same grade. Of the changes, 62{\%} were within one grade point. We find a statistically significant correlation between the modified SCS1 score and CS2 grade points. Students identify linked lists and class/object concepts among the most challenging. Student feedback on CS2 challenges and the adequacy of their CS1 preparations identify possible avenues for improving the CS1-CS2 transition.},
address = {Tampa, FL, USA},
author = {Layman, Lucas and Song, Yang and Guinn, Curry},
booktitle = {Proceedings of the 2020 ACM Southeast Conference (ACMSE 2020)},
doi = {10.1145/3374135.3385277},
file = {:C$\backslash$:/Users/laymanl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Layman, Song, Guinn - 2020 - Toward Predicting Success and Failure in CS2 A Mixed-Method Analysis.pdf:pdf},
pages = {8},
publisher = {ACM},
title = {{Toward Predicting Success and Failure in CS2 : A Mixed-Method Analysis}},
url = {https://arxiv.org/abs/2002.11813},
year = {2020}
}

@incollection{Shull2013,
abstract = {{\textcopyright} 2013 Springer-Verlag Berlin Heidelberg. All rights are reserved. In this chapter, we discuss recent progress and opportunities in empirical software engineering by focusing on a particular technology, Technical Debt (TD), which ties together many recent developments in the field. Recent advances in TD research are providing empiricists the chance to make more sophisticated recommendations that have observable impact on practice. TD uses a financial metaphor and provides a framework for articulating the notion of tradeoffs between the short-term benefits and the long-term costs of software development decisions. TD is seeing an explosion of interest in the practitioner community, and research in this area is quickly having an impact on practice. We argue that this is due to several strands of empirical research reaching a level of maturity that provides useful benefits to practitioners, who in turn provide excellent data to researchers. They key is providing observable benefit to practitioners, such as the ability to tie technical debt measures to business goals, and the ability to articulate more sophisticated value-based propositions regarding how to prioritize rework. TD is an interesting case study in how the maturing field of empirical software engineering research is paying dividends. It is only a little hyperbolic to call this a watershed moment for empirical study, where many areas of progress are coming to a head at the same time.},
author = {Shull, Forrest and Falessi, Davide and Seaman, Carolyn and Diep, Madeline and Layman, Lucas},
booktitle = {Perspectives on the Future of Software Engineering: Essays in Honor of Dieter Rombach},
doi = {10.1007/978-3-642-37395-4_12},
editor = {M{\"{u}}nch, J{\"{u}}rgen and Schmid, Klaus},
file = {:C$\backslash$:/Users/laymanl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Shull et al. - 2013 - Technical Debt Showing the Way for Better Transfer of Empirical Results.pdf:pdf},
isbn = {9783642373954},
keywords = {mypubs},
mendeley-tags = {mypubs},
pages = {179--190},
publisher = {Elsevier},
title = {{Technical Debt: Showing the Way for Better Transfer of Empirical Results}},
volume = {9783642373},
year = {2013}
}

@inproceedings{Layman2007b,
abstract = {The longer a fault remains in the code from the time it was injected, the more time it will take to fix the fault. Increasingly, automated fault detection (AFD) tools are providing developers with prompt feedback on recently-introduced faults to reduce fault fix time. If however, the frequency and content of this feedback does not match the developer's goals and/or workflow, the developer may ignore the information. We conducted a controlled study with 18 developers to explore what factors are used by developers to decide whether or not to address a fault when notified of the error. The findings of our study lead to several conjectures about the design of AFD tools to effectively notify developers of faults in the coding phase. The AFD tools should present fault information that is relevant to the primary programming task with accurate and precise descriptions. The fault severity and the specific timing of fault notification should be customizable. Finally, the AFD tool must be accurate and reliable to build trust with the developer.},
address = {Madrid, Spain},
author = {Layman, Lucas and Williams, Laurie and {St. Amant}, Robert},
booktitle = {First International Symposium on Empirical Software Engineering and Measurement (ESEM 2007)},
doi = {10.1109/ESEM.2007.11},
file = {:C$\backslash$:/Users/laymanl/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Layman, Williams, St. Amant - 2007 - Toward Reducing Fault Fix Time Understanding Developer Behavior for the Design of Automated Fault D.pdf:pdf},
isbn = {978-0-7695-2886-1},
issn = {1938-6451},
keywords = {AFD tools,Automatic control,Computer science,Error correction,Fault detection,Feedback,Frequency,Software engineering,Software measurement,Time measurement,Timing,automated fault detection tools,developer behavior,fault diagnosis,fault fix time,fault information,fault notification,fault severity,mypubs,software tools},
mendeley-tags = {mypubs},
month = {sep},
pages = {176--185},
publisher = {IEEE},
shorttitle = {Empirical Software Engineering and Measurement, 20},
title = {{Toward Reducing Fault Fix Time: Understanding Developer Behavior for the Design of Automated Fault Detection Tools}},
year = {2007}
}
